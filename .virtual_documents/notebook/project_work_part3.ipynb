


# Importing Essential Libraries
import pandas as pd 
import numpy as np   
import matplotlib.pyplot as plt
from scipy.fftpack import dct, idct
# Aesthetic settings for plots
plt.style.use('seaborn-v0_8')
plt.rcParams['figure.figsize'] = (10, 5)


#  Creating Norwegian Cities Data

# Information for the five cities (from Norwegian price zones)
# You can modify the price area codes based on Elhub data or a previous project
cities_data = {
    "price_area_code": ["NO1", "NO2", "NO3", "NO4", "NO5"],
    "city_name": ["Oslo", "Kristiansand", "Trondheim", "Tromsø", "Bergen"],
    "latitude": [59.9139, 58.1467, 63.4305, 69.6492, 60.39299],
    "longitude": [10.7522, 7.9956, 10.3951, 18.9560, 5.32415]
}

# Convert the data into a DataFrame
df_cities = pd.DataFrame(cities_data)

# Display the result to verify
df_cities





# Importing API Connection Libraries

import requests  # For sending and receiving HTTP requests
import datetime as dt  # For handling dates and times

# Function to Download Weather Data from Open-Meteo API

def download_weather_data(latitude: float, longitude: float, year: int):
    """
    Download historical weather data from the Open-Meteo API (ERA5 model)
    Includes the same variables used in Part 1 of the project.
    """

    start_date = f"{year}-01-01"
    end_date = f"{year}-12-31"

    url = "https://archive-api.open-meteo.com/v1/era5"

    params = {
        "latitude": latitude,
        "longitude": longitude,
        "start_date": start_date,
        "end_date": end_date,
        "hourly": [
            "temperature_2m",
            "precipitation",
            "wind_speed_10m",
            "wind_gusts_10m",
            "wind_direction_10m"
        ],
        "timezone": "Europe/Oslo"
    }

    response = requests.get(url, params=params)

    if response.status_code != 200:
        raise Exception(f"Error connecting to the API: {response.status_code}")

    data = response.json()

    # Build a DataFrame similar to the previous file
    df_weather = pd.DataFrame({
        "time": pd.to_datetime(data["hourly"]["time"]),
        "temperature_2m (°C)": data["hourly"]["temperature_2m"],
        "precipitation (mm)": data["hourly"]["precipitation"],
        "wind_speed_10m (m/s)": data["hourly"]["wind_speed_10m"],
        "wind_gusts_10m (m/s)": data["hourly"]["wind_gusts_10m"],
        "wind_direction_10m (°)": data["hourly"]["wind_direction_10m"],
    })

    print(f"Weather data for year {year} downloaded successfully ({len(df_weather)} records)")
    return df_weather





# Bergen coordinates from the previous DataFrame
lat_bergen = 60.39299
lon_bergen = 5.32415

# Download the data
df_bergen_2019 = download_weather_data(lat_bergen, lon_bergen, 2019)

# Display the first 5 rows
df_bergen_2019.head()


df_bergen_2019.columns


df_bergen_2019.isna().sum()


df_bergen_2019.describe()








# Temperature outlier detection via high-pass DCT + MAD thresholding
def plot_temperature_outliers(df, column="temperature_2m (°C)", 
                              cutoff=0.02, n_std=3.5, show_summary=True):
    """
    Detect temperature outliers using a DCT high-pass filter and a MAD-based threshold.
    Returns a DataFrame of outliers and renders a plot.
    """
    # Ensure the column exists
    if column not in df.columns:
        raise ValueError(f"Column '{column}' not found in DataFrame")

    # --- Step 1: Apply DCT ---
    temp = df[column].values
    temp_dct = dct(temp, norm="ortho")

    # Determine cutoff frequency index
    N = len(temp_dct)
    cutoff_index = int(N * cutoff)
    
    # Zero out low frequencies to keep only rapid variations (high-pass)
    temp_dct[:cutoff_index] = 0

    # --- Step 2: Inverse DCT to reconstruct the filtered signal ---
    temp_filtered = idct(temp_dct, norm="ortho")

    # --- Step 3: Compute MAD-based bounds for anomaly detection ---
    median_val = np.median(temp_filtered)
    mad = np.median(np.abs(temp_filtered - median_val))
    lower_bound = median_val - n_std * mad
    upper_bound = median_val + n_std * mad

    # Identify outliers
    is_outlier = (temp_filtered < lower_bound) | (temp_filtered > upper_bound)
    outliers = df[is_outlier]

    # --- Step 4: Plot results ---
    plt.figure(figsize=(14, 5))
    plt.plot(df["time"], temp, label="Temperature (°C)", color="#58a3c5", alpha=0.8)
    plt.scatter(outliers["time"], outliers[column], color="red", label="Outliers", s=12)
    plt.title("Temperature vs Time with Outliers (DCT High-Pass Filter)")
    plt.xlabel("Time")
    plt.ylabel("Temperature (°C)")
    plt.legend()
    plt.grid(True)
    plt.show()

    # --- Step 5: Summary statistics ---
    if show_summary:
        print(f"Number of outliers: {len(outliers)}")
        print(f"Percentage of data: {100 * len(outliers) / len(df):.2f}%")
        print(f"Lower bound: {round(lower_bound, 2)} | Upper bound: {round(upper_bound, 2)}")

    return outliers



# Test the function on Bergen 2019 data

outliers_bergen = plot_temperature_outliers(
    df_bergen_2019, 
    column="temperature_2m (°C)",
    cutoff=0.02,     # fraction of low frequencies to remove
    n_std=3.5        # MAD-multiples threshold for outliers
)



outliers_bergen.head(3)


from sklearn.neighbors import LocalOutlierFactor
import numpy as np
import matplotlib.pyplot as plt

# Detecting Precipitation Anomalies (LOF)

def plot_precipitation_anomalies(df, column="precipitation (mm)", contamination=0.01, show_summary=True):
    """
    Detect precipitation anomalies using the Local Outlier Factor (LOF) algorithm.
    
    Parameters:
        df (DataFrame): Weather data containing 'time' and precipitation columns.
        column (str): Name of the precipitation column.
        contamination (float): Expected proportion of outliers (e.g., 0.01 = 1%).
        show_summary (bool): Whether to print a summary of detected anomalies.
    
    Returns:
        DataFrame: A subset of outlier records.
        Also displays a plot and summary statistics.
    """

    # --- Step 1: Check if the required column exists ---
    if column not in df.columns:
        raise ValueError(f"Column '{column}' not found in DataFrame")

    # --- Step 2: Prepare data for the LOF algorithm ---
    X = df[[column]].values  # use only the precipitation column

    # Create the LOF model
    lof = LocalOutlierFactor(n_neighbors=20, contamination=contamination)

    # Predict outliers (-1 = outlier, 1 = normal)
    y_pred = lof.fit_predict(X)

    # Identify outlier rows
    is_outlier = y_pred == -1
    outliers = df[is_outlier]

    # --- Step 3: Plot results ---
    plt.figure(figsize=(14, 5))
    plt.plot(df["time"], df[column], label="Precipitation (mm)", color="#3389EA", alpha=0.7)
    plt.scatter(outliers["time"], outliers[column], color="red", label="Outliers", s=15)
    plt.title(f"Precipitation vs Time with LOF Outliers (contamination={contamination})")
    plt.xlabel("Time")
    plt.ylabel("Precipitation (mm)")
    plt.legend()
    plt.grid(True)
    plt.show()

    # --- Step 4: Summary ---
    if show_summary:
        print(f"Number of outliers: {len(outliers)}")
        print(f"Percentage of data: {100 * len(outliers) / len(df):.2f}%")
        print("Top 5 anomalous values:")
        display(outliers.sort_values(column, ascending=False).head())

    return outliers


# Test the function on Bergen 2019 data

outliers_precip = plot_precipitation_anomalies(
    df_bergen_2019,
    column="precipitation (mm)",
    contamination=0.01  
)





#  load production data
elhub_df = pd.read_csv("elhub_production.csv")
elhub_df.head()





elhub_df.isnull().sum()


from statsmodels.tsa.seasonal import STL

def stl_decompose_simple(
    df,
    area="NO1",
    production_group="hydro",
    period_length=24*7,
    seasonal=25,
    trend=601,
    robust=True
):
    """
    Perform STL (Seasonal-Trend decomposition using Loess) on Elhub-style
    electricity production data and return both the figure and result object.

    Parameters
    ----------
    df : pandas.DataFrame
        DataFrame containing at least:
        ['startTime', 'priceArea', 'productionGroup', 'quantityKwh'].
    area : str, default="NO1"
        Electricity price area to filter (e.g., "NO1", "NO2", ...).
    production_group : str, default="hydro"
        Production group to analyze (e.g., "hydro", "wind", "solar").
    period_length : int, default=24*7
        Period (in hours) for the seasonal component — here one week.
    seasonal : int, default=25
        Length of the seasonal smoother.
    trend : int, default=601
        Length of the trend smoother.
    robust : bool, default=True
        Whether to use a robust fitting method to reduce the impact of outliers.

    Returns
    -------
    fig : matplotlib.figure.Figure
        The Matplotlib figure displaying trend, seasonal, and residual components.
    result : statsmodels.tsa.seasonal.STLResult
        The STL decomposition result object containing component series.
    s"""

    # Convert and clean datetime
    df["startTime"] = pd.to_datetime(df["startTime"], errors="coerce", utc=True)
    df = df.dropna(subset=["startTime"]).set_index("startTime").sort_index()

    # Filter data
    sub = df[(df["priceArea"] == area) & (df["productionGroup"] == production_group)]
    if sub.empty:
        print("No data found for this area or production group.")
        return None, None

    # Prepare numeric values
    y = pd.to_numeric(sub["quantityKwh"], errors="coerce")
    y = y.resample("h").sum().interpolate()

    # Run STL
    stl = STL(y, period=period_length, seasonal=seasonal, trend=trend, robust=robust)
    result = stl.fit()

    # Plot
    fig = result.plot()
    fig.set_size_inches(12, 8)
    fig.suptitle(f"STL Decomposition — {production_group.capitalize()} ({area})", fontsize=14)

    # Close figure to prevent double rendering
    plt.close(fig)

    return fig, result


def stl_decompose_simple(
    df,
    area="NO1",
    production_group="hydro",
    period_length=24*7,
    seasonal=25,
    trend=601,
    robust=True
):
    """
    Perform STL (Seasonal-Trend decomposition using Loess) on Elhub-style
    electricity production data and return both the figure and result object.

    Parameters
    ----------
    df : pandas.DataFrame
        DataFrame containing at least:
        ['startTime', 'priceArea', 'productionGroup', 'quantityKwh'].
    area : str, default="NO1"
        Electricity price area to filter (e.g., "NO1", "NO2", ...).
    production_group : str, default="hydro"
        Production group to analyze (e.g., "hydro", "wind", "solar").
    period_length : int, default=24*7
        Period (in hours) for the seasonal component — here one week.
    seasonal : int, default=25
        Length of the seasonal smoother.
    trend : int, default=601
        Length of the trend smoother.
    robust : bool, default=True
        Whether to use a robust fitting method to reduce the impact of outliers.

    Returns
    -------
    fig : matplotlib.figure.Figure
        The Matplotlib figure displaying trend, seasonal, and residual components.
    result : statsmodels.tsa.seasonal.STLResult
        The STL decomposition result object containing component series.
    s"""

    # Convert and clean datetime
    df["startTime"] = pd.to_datetime(df["startTime"], errors="coerce", utc=True)
    df = df.dropna(subset=["startTime"]).set_index("startTime").sort_index()

    # Filter data
    sub = df[(df["priceArea"] == area) & (df["productionGroup"] == production_group)]
    if sub.empty:
        print("No data found for this area or production group.")
        return None, None

    # Prepare numeric values
    y = pd.to_numeric(sub["quantityKwh"], errors="coerce")
    y = y.resample("h").sum().interpolate()

    # Run STL
    stl = STL(y, period=period_length, seasonal=seasonal, trend=trend, robust=robust)
    result = stl.fit()

    # Plot
    fig = result.plot()
    fig.set_size_inches(12, 8)
    fig.suptitle(f"STL Decomposition — {production_group.capitalize()} ({area})", fontsize=14)

    # Close figure to prevent double rendering
    plt.close(fig)

    return fig, result



from statsmodels.tsa.seasonal import STL
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.ticker as mtick

def stl_decompose_pretty(
    df,
    area="NO1",
    production_group="hydro",
    period_length=24*7,
    seasonal=25,
    trend=601,
    robust=True,
    dpi=150,
    figsize=(14, 9)
):
    # 1) وقت وفهرسة
    df = df.copy()
    df["startTime"] = pd.to_datetime(df["startTime"], errors="coerce", utc=True)
    df = df.dropna(subset=["startTime"]).set_index("startTime").sort_index()

    # 2) تصفية
    sub = df[(df["priceArea"] == area) & (df["productionGroup"] == production_group)]
    if sub.empty:
        print("No data found for this area or production group.")
        return None, None

    # 3) بناء السلسلة (ساعة)
    y = (pd.to_numeric(sub["quantityKwh"], errors="coerce")
           .resample("h").sum()
           .asfreq("h")
           .interpolate(limit=6))

    # 4) STL
    stl = STL(y, period=period_length, seasonal=seasonal, trend=trend, robust=robust)
    result = stl.fit()

    # 5) الرسم
    fig = result.plot(observed=True)
    fig.set_size_inches(*figsize)
    fig.set_dpi(dpi)
    fig.set_constrained_layout(True)
    fig.subplots_adjust(hspace=0.35)

    axes = fig.axes
    fig.suptitle(f"STL Decomposition — {production_group.capitalize()} ({area})", fontsize=16, y=0.98)
    titles = ["Observed", "Trend", "Seasonal", "Residual"]
    for ax, t in zip(axes, titles):
        ax.set_title(t, fontsize=13, pad=6)
        ax.grid(True, linewidth=0.5, alpha=0.25)
        ax.spines[['top', 'right']].set_visible(False)
        ax.tick_params(labelsize=11)
        ax.margins(x=0.01, y=0.05)
        ax.yaxis.set_major_formatter(mtick.FuncFormatter(lambda v,_: f"{v/1e6:.1f}M"))

        for line in ax.lines:
            line.set_linewidth(1.2)
            line.set_alpha(0.9)

    plt.close(fig)
    return fig, result



fig, res = stl_decompose_simple(
    elhub_df,
    area="NO5",
    production_group="hydro",
    period_length=24*7,  # one week of hourly data
    seasonal=25,
    trend=601,
    robust=True
)


fig





from scipy.signal import spectrogram

def production_spectrogram(
    df: pd.DataFrame,
    area: str = "NO1",
    production_group: str = "hydro",
    nperseg: int = 256,                  # window length (samples)
    noverlap: int = 128,                 # window overlap (samples)
    
    time_col: str = "startTime",
    area_col: str = "priceArea",
    group_col: str = "productionGroup",
    value_col: str = "quantityKwh",
):
    """
    Build a spectrogram for Elhub production data and return a Matplotlib Figure.

    Parameters
    ----------
    df : pd.DataFrame
        Table with at least [time_col, area_col, group_col, value_col].
    area : str
        Electricity price area filter (e.g. "NO1").
    production_group : str
        Production group filter (e.g. "hydro", "wind", ...).
    nperseg : int
        Window length in samples (hourly data ⇒ samples are hours).
    noverlap : int
        Overlap between windows in samples.
    time_col, area_col, group_col, value_col : str
        Column names in `df`.

    Returns
    -------
    fig : matplotlib.figure.Figure | None
        Figure of the spectrogram, or None if no data matches the filters.
    """

    # Copy & parse time
    s = df.copy()
    s[time_col] = pd.to_datetime(s[time_col], errors="coerce", utc=True)
    s = s.dropna(subset=[time_col])

    # Filter by area and production group
    s = s[(s[area_col] == area) & (s[group_col] == production_group)]
    if s.empty:
        return None

    # Build a time-indexed series, hourly and numeric
    ts = pd.DataFrame({
        time_col: s[time_col].values,
        "value": pd.to_numeric(s[value_col], errors="coerce"),
    }).dropna()

    ts = ts.set_index(time_col).sort_index()
    ts = ts.resample("h").sum().interpolate(limit_direction="both")

    x = ts["value"].astype(float).to_numpy()
    if x.size == 0:
        return None

    # Sampling rate: hourly ⇒ 24 samples/day
    fs = 24.0

    # Clamp overlap
    noverlap = max(0, min(noverlap, nperseg - 1))

    # Spectrogram
    f, t, Sxx = spectrogram(
        x, fs=fs, nperseg=nperseg, noverlap=noverlap,
        scaling="density", mode="magnitude"
    )

    # Plot
    fig, ax = plt.subplots(figsize=(10, 4))
    im = ax.pcolormesh(t, f, Sxx, shading="gouraud", cmap="viridis")
    ax.set_title(f"Spectrogram — {production_group.capitalize()} ({area})")
    ax.set_xlabel("Time (days)")
    ax.set_ylabel("Frequency (cycles/day)")
    fig.colorbar(im, ax=ax, label="Magnitude")
    fig.tight_layout()

    # Prevent double display in notebooks
    plt.close(fig)
    return fig


fig_spec = production_spectrogram(
    elhub_df,
    area="NO5",
    production_group="hydro",
    nperseg=256,          
    noverlap=128,        
    time_col="startTime",
    area_col="priceArea",
    group_col="productionGroup",
    value_col="quantityKwh",
)

fig_spec



